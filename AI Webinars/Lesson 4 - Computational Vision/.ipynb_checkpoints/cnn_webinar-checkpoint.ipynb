{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial sobre Deep Learning em Python para iniciantes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste tutorial passo-a-passo de Keras, você vai aprender como construir uma rede neural convolucional (CNN) em Python!\n",
    "\n",
    "Na verdade, estaremos treinando um classificador de dígitos manuscritos que possui mais de 98% de precisão no famoso banco de dados MNIST.\n",
    "\n",
    "Antes de começarmos, você deve saber que este guia é voltado para iniciantes que estão interessados em _Deep Learning_ aplicada.\n",
    "\n",
    "Nosso objetivo é apresentá-lo a uma das bibliotecas mais populares e poderosas para a construção de redes neurais do Python. Isso significa que vamos pular uma grande parte da teoria e da matemática, mas também vamos te indicar recursos excelentes para que você possa aprender sobre esses temas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 1: Importar bibliotecas e módulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar importando _NumPy_ e definindo uma seed para o gerador de números pseudoaleatórios do computador. Isso nos permite reproduzir os resultados do nosso script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NumPy\n",
    "import numpy as np\n",
    "np.random.seed(123) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, vamos importar o modelo **Sequential** do Keras. Ou seja, uma pilha linear de camadas de redes neurais, e é perfeito para o tipo de _CNN feed-forward_ que estamos construindo neste tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Modelo do Keras\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, vamos importar as camadas principais do Keras. Estas são as camadas que são usadas em praticamente qualquer rede neural:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Camadas principais do Keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos importar as camadas CNN do Keras. Estas são as camadas convolucionais que nos ajudarão a treinar eficientemente em dados de imagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Camadas CNN do Keras\n",
    "from keras.layers import Convolution2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, vamos importar alguns utilitários. Isso nos ajudará a transformar nossos dados mais tarde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utilitários\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 2: Carregar dados de imagens do MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST é um ótimo banco de dados para começar a aprender profundamente sobre _Deep Learning_ e visão computacional. É um desafio suficientemente grande para necessitar o uso de redes neurais, mas pode ser feito em um único computador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convenientemente, a biblioteca Keras também o inclui. Podemos carregá-lo assim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Carregando dados do MNIST\n",
    "from keras.datasets import mnist\n",
    " \n",
    "# Carrega dados já embaralhados do MNIST para os train e test sets.\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar a forma do banco de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ótimo, então parece que temos 60 mil amostras em nosso banco de dados de treino, e essas imagens possuem dimensões de 28 pixels x 28 pixels cada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em geral, quando se trabalha com visão computacional, é útil plotar visualmente os dados antes de trabalhar com qualquer algoritmo. É uma verificação rápida que pode evitar erros que são facilmente evitáveis (como uma interpretação errada das dimensões dos dados)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 3: Pré-processar dados de entrada para o Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ao usar o _backend_ Theano, você deve declarar explicitamente uma dimensão para a profundidade da imagem de entrada. Por exemplo, uma imagem colorida com todos os 3 canais RGB terá uma profundidade de 3.\n",
    "\n",
    "Nossas imagens MNIST possuem apenas uma profundidade de 1, mas devemos declarar explicitamente isso.\n",
    "\n",
    "Em outras palavras, queremos transformar nosso conjunto de dados de forma (n, largura, altura) para (n, profundidade, largura, altura).\n",
    "\n",
    "Veja como podemos fazer isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remodelando dados de entrada\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para confirmar, podemos imprimir novamente as dimensões de **X_train**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O passo final de pré-processamento dos dados de entrada é converter o nosso tipo de dados para **float32** e normalizar nossos valores de dados para o intervalo [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convertendo tipo de dados e normalizando valores\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, nossos dados de entrada estão prontos para treinamento de modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 4: Pré-processar rótulos de classe para o Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, vamos dar uma olhada no formato dos nossos _labels_ (rótulos) de dados da classe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm ... temos um problema. Deveríamos ter 10 classes diferentes, uma para cada dígito, mas parece que só temos um _array_ de 1 dimensão. Vamos dar uma olhada nos _labels_ das primeiras 10 amostras de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aí está o problema. Os dados **y_train** e **y_test** não estão divididos em 10 _labels_ de classe distintos, mas estão sendo representados por um único _array_ com os valores da classe.\n",
    "\n",
    "Podemos resolver isso facilmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convertendo arrays unidimensionais para matrizes de 10 dimensões\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos dar uma outra olhada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aí sim, muito melhor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 5: Definir a arquitetura do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora estamos prontos para definir nossa arquitetura do modelo. Num trabalho real de P&D (Pesquisa e Desenvolvimento), os pesquisadores passarão uma quantidade considerável de tempo estudando arquiteturas de modelos.\n",
    "\n",
    "Para não travar nosso andamento, não vamos discutir a teoria ou a matemática aqui.\n",
    "\n",
    "Além disso, quando você está apenas começando, você pode apenas replicar arquiteturas comprovadas de documentos acadêmicos ou usar exemplos existentes. Aqui está uma lista de [exemplos de implementações em Keras](https://github.com/fchollet/keras/tree/master/examples).\n",
    "\n",
    "Vamos começar por declarar um formato de modelo seqüencial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declarando modelo \"Sequential\"\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, declaramos a camada de entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Camada de entrada da CNN\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O parâmetro de entrada do formato deve possuir o formato de 1 amostra. Neste caso, é o mesmo (28, 28, 1) que corresponde à (largura, altura, profundidade) de cada imagem de dígito.\n",
    "\n",
    "Mas o que representam os três primeiros parâmetros? Eles correspondem ao número de linhas em cada núcleo de convolução, o número de colunas em cada núcleo de convolução e o número de filtros de convolução a se usar, respectivamente.\n",
    "\n",
    "* Nota: O tamanho do passo é (1,1) por definição, e pode ser ajustado usando o parâmetro '_subsample_'.\n",
    "\n",
    "Podemos confirmar isso imprimindo a forma da saída atual do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 26, 26, 32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, podemos simplesmente adicionar mais camadas ao nosso modelo, como se estivéssemos construindo legos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais uma vez, não vamos entrar demais na teoria, mas é importante destacar a camada **Dropout** que acabamos de adicionar. Este é um método para regularizar o nosso modelo de modo a evitar a superposição. Você pode ler mais sobre isso [aqui](https://www.quora.com/How-does-the-dropout-method-work-in-deep-learning-And-why-is-it-claimed-to-be-an-effective-trick-to-improve-your-network).\n",
    "\n",
    "O **MaxPooling2D** é uma maneira de reduzir o número de parâmetros em nosso modelo, passando um filtro de agrupamento 2x2 na camada anterior e pegando valor o máximo dos 4 valores do filtro 2x2.\n",
    "\n",
    "Até agora, para os parâmetros do modelo, adicionamos duas camadas de convolução. Para completar a arquitetura do nosso modelo, vamos adicionar uma camada totalmente conectada e depois a camada de saída:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Camadas profundas totalmente conectadas\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para camadas densas, o primeiro parâmetro é o tamanho da saída (_output size_) da camada. O Keras administra automaticamente as conexões entre as camadas.\n",
    "\n",
    "Observe que a camada final possui saídas com tamanho 10, que correspondem às 10 classes de dígitos.\n",
    "\n",
    "Observe também que os pesos das camadas de convolução devem ser achatados (transformados em unidimensionais) antes de serem passados para a camada densa completamente conectada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, tudo o que precisamos fazer é definir a função de perda e o otimizador, e então estaremos prontos para treiná-lo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 6: Compilar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora estamos quase lá! A parte difícil já acabou.\n",
    "\n",
    "Nós precisamos apenas compilar o modelo e estaremos prontos para treiná-lo. Quando compilamos o modelo, declaramos a função de perda e o otimizador (SGD, Adam, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compilando modelo\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Keras possui uma variedade de [funções de perda](https://keras.io/losses/) e [otimizadores](https://keras.io/optimizers/) à disposição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 7: Adequar o modelo aos dados de treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para adequar o modelo, tudo que precisamos fazer é declarar o tamanho do lote (batch_size) e o número de épocas (epochs) a serem treinados, e depois passá-los no dados de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 28s - loss: 0.2434 - acc: 0.9249    \n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 26s - loss: 0.0915 - acc: 0.9727    \n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 26s - loss: 0.0694 - acc: 0.9797    \n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 26s - loss: 0.0585 - acc: 0.9822    \n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 26s - loss: 0.0509 - acc: 0.9836    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff5eda12b38>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adequando modelo do Keras\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=75, epochs=5, verbose=1)\n",
    "# Epoch 1/10\n",
    "# 7744/60000 [==>...........................] - ETA: 96s - loss: 0.5806 - acc: 0.8164"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fácil, não?\n",
    "\n",
    "Você também pode usar uma variedade de [callbacks](https://keras.io/callbacks/) para definir regras de parada antecipada, salvar os pesos do modelo ao longo do caminho ou registrar o histórico de cada período de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 8: Avaliar modelo com os dados de treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos avaliar o nosso modelo com os dados para testes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.030081725770416234, 0.99060000000000004]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando modelos do Keras\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parabéns ... você chegou ao final deste tutorial de Keras!\n",
    "\n",
    "Acabamos de concluir um tour com um turbilhão de funcionalidades do Keras, mas nós apenas tocamos o começo. Espero que você tenha adquirido as bases para explorar ainda mais o que o Keras tem a oferecer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
