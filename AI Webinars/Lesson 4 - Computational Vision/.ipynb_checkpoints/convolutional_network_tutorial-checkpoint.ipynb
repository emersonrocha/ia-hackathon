{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network \n",
    "\n",
    "\n",
    "## O que inspirou as redes convolutivas?\n",
    "\n",
    "CNNs são modelos de inspiração biológica inspirados na pesquisa de D. H. Hubel e T. N. Wiesel. Eles propuseram uma explicação para a forma como os mamíferos percebem visualmente o mundo ao seu redor usando uma arquitetura em camadas de neurônios no cérebro, e isso, por sua vez, inspirou engenheiros a tentar desenvolver mecanismos semelhantes de reconhecimento de padrões em visão computacional.\n",
    "\n",
    "Na sua hipótese, dentro do córtex visual, as respostas funcionais complexas geradas por \"células complexas\" são construídas a partir de respostas mais simples de \"células simples\".\n",
    "\n",
    "Para casos, células simples responderiam a bordas orientadas, etc., enquanto células complexas também responderiam a bordas orientadas, mas com um grau de invariância espacial.\n",
    "\n",
    "Existem campos receptivos para células, onde uma célula responde a uma soma de entradas de outras células locais.\n",
    "\n",
    "A arquitetura das redes nervosas convolutivas profundas foi inspirada pelas idéias mencionadas acima\n",
    "- conexões locais\n",
    "- layering  \n",
    "- invariância espacial (mudar o sinal de entrada resulta em um sinal de saída igualmente deslocado). A maioria de nós é capaz de reconhecer caras específicas sob uma variedade de condições porque aprendemos a abstração. Essas abstrações são invariantes ao tamanho, contraste, rotação, orientação\n",
    " \n",
    "No entanto, continua a ser visto se esses mecanismos computacionais de redes neurais convolutivas são semelhantes aos mecanismos de computação que ocorrem no sistema visual primata\n",
    "\n",
    "- operação de convolução\n",
    "- pesos compartilhados\n",
    "- pooling/subsampling \n",
    "\n",
    "## Como funciona?\n",
    "\n",
    "\n",
    "![alt text](https://images.nature.com/w926/nature-assets/srep/2016/160610/srep27755/images_hires/srep27755-f1.jpg \"Logo Title Text 1\")\n",
    "![alt text](https://www.mathworks.com/content/mathworks/www/en/discovery/convolutional-neural-network/jcr:content/mainParsys/image_copy.adapt.full.high.jpg/1497876372993.jpg \"Logo Title Text 1\")\n",
    "\n",
    "### Passo 1 - Prepare o dataset8 de imagens\n",
    "\n",
    "![alt text](http://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure1.png \"Logo Title Text 1\")\n",
    "\n",
    "- Toda imagem é uma matriz de valores de pixels.\n",
    "- O intervalo de valores que podem ser codificados em cada pixel depende do tamanho do bit.\n",
    "- Mais comumente, temos pixels de 8 bits ou de tamanho de byte. Assim, a possível gama de valores que um único pixel pode representar é [0, 255].\n",
    "- No entanto, com imagens coloridas, particularmente imagens RGB (Red, Green, Blue), a presença de canais de cores separados (3 no caso de imagens RGB) introduz um campo adicional de \"profundidade\" para os dados, fazendo a entrada 3- dimensional.\n",
    "- Portanto, para uma determinada imagem RGB de tamanho, digamos pixels 255 × 255 (Largura x Altura), teremos 3 matrizes associadas a cada imagem, uma para cada um dos canais de cores.\n",
    "- Assim, a imagem na sua totalidade, constitui uma estrutura tridimensional chamada Volume de entrada (255x255x3).\n",
    "\n",
    "Bons datasets de treinamento são CIFAR, CoCo e MNIST.\n",
    "![alt text](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "### Step 2 - Convolução \n",
    "\n",
    "![alt text](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/more_images/Convolution_schematic.gif \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](http://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure_2.png \"Logo Title Text 1\")\n",
    "\n",
    "- Uma convolução é um procedimento ordenado em que duas fontes de informação estão entrelaçadas.\n",
    "\n",
    "- Um kernel (também chamado de filtro) é uma matriz de tamanho menor em comparação com as dimensões de entrada da imagem, que consiste em entradas de valor real.\n",
    "\n",
    "- Kernels são então convolvidos com o volume de entrada para obter os chamados \"mapas de ativação\" (também chamados de mapas de recursos).\n",
    "- Os mapas de ativação indicam regiões \"ativadas\", ou seja, regiões onde os recursos específicos para o kernel foram detectados na entrada.\n",
    "\n",
    "- Os valores reais da matriz do kernel mudam com cada iteração de aprendizagem sobre o conjunto de treinamento, indicando que a rede está aprendendo a identificar quais regiões são importantes para extrair recursos dos dados.\n",
    "\n",
    "- Nós calculamos o produto ponto entre o kernel e a matriz de entrada. - O valor convolvido obtido somando os termos resultantes do produto ponto produz uma única entrada na matriz de ativação.\n",
    "\n",
    "- A seleção do patch é então deslizada (para a direita ou para baixo quando o limite da matriz é atingida) por uma certa quantidade chamada valor \"stride\" e o processo é repetido até a imagem de entrada inteira ser processada. - O processo é realizado para todos os canais de cores.\n",
    "\n",
    "- Em vez de conectar cada neurônio a todos os pixels possíveis, especificamos uma região bidimensional chamada 'campo receptivo [14]' (digamos de tamanho 5 × 5 unidades) que se estende para toda a profundidade da entrada (5x5x3 para uma entrada de canal de 3 cores ), dentro dos quais os pixels abrangidos estão totalmente conectados à camada de entrada da rede neural. É sobre essas pequenas regiões que as seções transversais da camada de rede (cada uma constituídas por vários neurônios (chamadas \"colunas de profundidade\") operam e produzem o mapa de ativação. (reduz a complexidade computacional)\n",
    "\n",
    "![alt text](http://i.imgur.com/g4hRI6Z.png \"Logo Title Text 1\")\n",
    "![alt text](http://i.imgur.com/tpQvMps.jpg \"Logo Title Text 1\")\n",
    "![alt text](http://i.imgur.com/oyXkhHi.jpg \"Logo Title Text 1\")\n",
    "![alt text](http://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure_5.png \"Logo Title Text 1\")\n",
    "\n",
    "Grande recurso sobre a descrição da convolução (discreta vs contínua) e a transformada de Fourier\n",
    "\n",
    "http://timdettmers.com/2015/03/26/convolution-deep-learning/\n",
    "\n",
    "\n",
    "###  Step 3 - Pooling\n",
    "![alt text](http://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure_6.png \"Logo Title Text 1\")\n",
    "\n",
    "- Pooling reduz as dimensões espaciais (Largura x Altura) do Volume de entrada para a próxima camada convolucional. Não afeta a dimensão de profundidade do Volume. \n",
    "- A transformação é realizada tomando o valor máximo dos valores observáveis na janela (chamado \"MaxPooling\"), ou tomando a média dos valores. O agrupamento máximo foi favorecido em relação a outros devido às suas melhores características de desempenho.\n",
    "- também chamado de downsampling\n",
    "\n",
    "###  Step 4 - Normalização (ReLU no nosso caso)\n",
    "\n",
    "![alt text](http://xrds.acm.org/blog/wp-content/uploads/2016/06/CodeCogsEqn-3.png \"Logo Title Text 1\")\n",
    "\n",
    "Normalização (mantenha a matemática rompida ao transformar todos os números negativos em 0) (RELU), uma pilha de imagens torna-se uma pilha de imagens sem valores negativos.\n",
    "\n",
    "Repita as etapas 2-4 várias vezes. Mais, imagens menores (feature maps criados em cada camada)\n",
    "\n",
    "### Step 5 - Regularization \n",
    "\n",
    "- O dropout força uma rede neural artificial para aprender múltiplas representações independentes dos mesmos dados, alterando aleatoriamente os neurônios na fase de aprendizagem.\n",
    "- O dropout é uma característica vital em quase todas as implementações de rede neural de última geração.\n",
    "- Para executar o dropout de uma camada, você ajusta aleatoriamente alguns dos valores da camada para 0 durante a propagação direta.\n",
    "\n",
    "Veja [this](http://iamtrask.github.io/2015/07/28/dropout/)\n",
    "\n",
    "![alt text](https://i.stack.imgur.com/CewjH.png \"Logo Title Text 1\")\n",
    "\n",
    "###  Step 6 - Conversão de Probabilidade\n",
    "\n",
    "No final da nossa rede (a camada das saidas), aplicaremos uma função softmax para converter as saídas em valores de probabilidade para cada classe.\n",
    "\n",
    "![alt text](https://1.bp.blogspot.com/-FHDU505euic/Vs1iJjXHG0I/AAAAAAABVKg/x4g0FHuz7_A/s1600/softmax.JPG \"Logo Title Text 1\")\n",
    "\n",
    "\n",
    "###  Step 7 - Escolha a saida mais provável (valor máximo de probabilidade)\n",
    "\n",
    "argmax(softmax_outputs)\n",
    "\n",
    "Essas 7 etapas são uma passagem para a frente pela rede.\n",
    "\n",
    "## Então, como aprendemos os números mágicos?\n",
    "\n",
    "- Podemos aprender recursos e valores de peso através de backpropagation\n",
    "\n",
    "![alt text](http://www.robots.ox.ac.uk/~vgg/practicals/cnn/images/cover.png \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/cnn-toupload-final-151117124948-lva1-app6892/95/convolutional-neural-networks-cnn-52-638.jpg?cb=1455889178 \"Logo Title Text 1\")\n",
    "\n",
    "Os outros hiperparâmetros são definidos pelos seres humanos e são um campo de pesquisa ativo (achando os melhores)\n",
    "\n",
    "isto é - número de neurônios, número de recursos, tamanho dos recursos, tamanho da janela, tamanho da janela, passo da janela\n",
    "\n",
    "\n",
    "## Quando é um bom momento para usá-lo?\n",
    "\n",
    "- Para classificar imagens\n",
    "- Para gerar imagens\n",
    "\n",
    "![alt text](https://nlml.github.io/images/convnet_diagram.png \"Logo Title Text 1\")\n",
    "\n",
    "Mas também pode ser aplicado a quaisquer dados espaciais 2D ou 3D. Imagens. Mesmo som e texto. Uma regra de ouro é se você dados são tão úteis se você trocar as linhas e as colunas, como dados do cliente, então você não pode usar uma CNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
